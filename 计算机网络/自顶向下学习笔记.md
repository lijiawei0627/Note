#  一、计算机网络和因特网

## 因特网

当一台端系统要向另一台端系统发送数据时，发送端系统先将数据分段，当分组发送到目的端系统之后，在那里被装配成初始数据

### 端系统

便携机、智能手机、平板电脑、电视、游戏机、温度调节装置、家用安全系统、家用电器、手表、眼镜、汽车、运输控制系统等正在与因特网相连。用因特网术语来说，所有这些设备都称为**主机或端系统**

**端系统通过通信链路和分组交换机连接到一 起**

### 分组交换机

市面上流行着各种类型、各具特色的分组交换机，但在当今的因特网中，两种最著名的类型是**路由器和链路层交换机**

### `ISP`

**端系统通过因特网服务提供商`（Internet Service Provider, ISP）`接入因特网**，包括如 本地电缆或电话公司那样的住宅区`ISP`、公司`ISP`、大学`ISP`,在机场、旅馆、咖啡店和其 他公共场所提供`WiFi`接入的`ISP`,以及为智能手机和其他设备提供移动接入的蜂窝数据 `ISP`。**每个`ISP`自身就是一个由多台分组交换机和多段通信链路组成的网络**

## 网络边缘

### 接入网

**指将端系统物理连接到其边缘路由器（edge router）的网络。边缘路由器是端系统到任何其他远程端系统的路径上的第一台路由器。**

#### 家庭接入

宽带住宅接入有两种最流行的类型：数字用户线（`Digital Subscriber Line, DSL`）和电缆。

#### 企业（和家庭）接入：以太网和`WIFI`

在公司和大学校园以及越来越多的家庭环境中，使用局域网（LAN）将端系统连接到边缘路由器。尽管有许多不同类型的局域网技术，但是以太网到目前为止 是公司、大学和家庭网络中最为流行的接入技术。

### 物理媒体

#### 引导型媒体

导引型媒体, 电波沿着固体媒体前行，如**双绞铜线、同轴电缆和光纤**。

* 双绞铜线

  最便宜并且最常用的导引型传输媒体是双绞铜线。一百多年来，它一直用于电话网。 

* 同轴电缆

* 光纤

  光纤是一种细而柔软的、能够导引光脉冲的媒体，每个脉冲表示一个比特。一根光纤能够支持极高的比特速率，高达数十甚至数百`Gbps`。

#### 非引导型媒体

非导引型媒体，电波在空气或外层空间中传播，例如在无线局域网或数字卫星频道中。 

# 二、网络核心

## 分组交换

为了从源端系统向目的端系统发送一个报文，源将长报文**划分为较小的数据块**，称之为分组 （packet）。在源和目的地之间，每个分组都**通过通信链路和分组交换机传送**。

**之所以要将长报文划分为较小的数据块，是因为假如你的一个数据包有`100GB`，那么这个路由器就得有能存`100Gb的`容量，可是发送1`00GB`的概率是极少数的，那把路由器设计成`100Gb`明显是浪费的，这是其中原因之一**

### 存储转发传输

**存储转发传输是指在交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。**

如果一个分组的一部分已经到达了路由器，并且该路由器应用了存储转发机制，那么此时它还不能传输已经接收的比特，而是必须先缓存（即“存储”）该分组的比特。仅当路由器已经接收完了该分组的所有比特后，它才能开始向出链路传输（即“转 发”）该分组

### 排队时延和分组丢失

对于每条相连的链路，该分组交换机具有一个输出缓存（output buffer,也称为输出队列（output queue））,它用于存储路由器准备发往那条链路的分组。如果到达的分组需要传输到某条链路，但发现**该链路正忙于传输其他分组，该到达分组必须在输出缓存中等待**。因此，**除了存储转发时延以外，分组还要承受输出缓存的排队时延。**

因为缓存空间的大小是有限的，一个到达的分组可能发现**该缓存已被其他等待传输的分组完全充满了**。在此情况下，将**出现分组丢失（丢包）**（packet loss）,到达的分组或已经排队的分组之一将被丢弃。 

### 转发表和路由选择协议

每个端系统具有一个`IP`地址。当源主机要向目的端系统发送一个分组时，源在该**分组的首部包含了目的地的`IP`地址**。如同邮政地址那样，该**地址具有一种等级结构**。当一个分组到达网络中的路由器时，**路由器检查该分组的目的地址的一部分，并向一台相邻路由器转发该分组**。更特别的是，**每台路由器具有一个转发表** (forwarding table),用于**将目的地址(或目的地址的一部分)映射成为输出链路**。当某分组到达一台路由器时，路由器检查该地址，并用这个目的地址搜索其转发表，以发现适当的出链路。路由器则将分组导向该出链路。 

**端到端选路过程可以用一个不使用地图而喜欢问路的汽车驾驶员来类比**

## 电路交换

**通过网络链路和交换机移动数据有两种基本方法：电路交换（circuit switching）和分 组交换（packet switching）** 

在电路交换网络中，在端系统间通信会话期间，**预留了端系统间沿路径通信所需要的资源**（缓存，链路传输速率）。在分组交换网络中，这些资源则不是预留的；会话的报文 按需使用这些资源，其后果可能是不得不等待（即排队）接入通信线路。**一个简单的类比是，考虑两家餐馆，一家需要顾客预订，而另一家不需要预订，但不保证能安排顾客。**

传统的电话网络是电路交换网络的例子。考虑当一个人通过电话网向另一个人发送信 息（语音或传真）时所发生的情况。**在发送方能够发送信息之前，该网络必须在发送方和接收方之间建立一条连接，该连接被称为一条电路**。当网络创建这种电路时，它也在连接期间在该网络链路上预留了恒定的传输速率（表示为每条链路传输容量的一部分）。

![image-20200603091343460](http://img.lijiawei0627.xyz/img/image-20200603091343460.png)

### 分组交换和电路交换的对比

* 分组交换
  * 优点：设计简单，成本低；提供了比电路交换更好的带宽共享；资源利用率很高
  * 缺点：存在延时，不具有实时性；会造成通信阻塞；存在无用的重复数据；可能会出现丢包情况

* 电路交换
  * 优点：传输速度快、高效、实时
  * 缺点：资源利用率低，新建连接需要占据一定时间，甚至比通话时间还长

## 网络的网络

网络的网络不仅有**多个竞争的第一层`ISP`**（全球传输`ISP`）,而且在一个区域可能有**多个竞争的区域`ISP`**。在这样的等级结构中，每个接入`ISP`向其连接的区域`ISP`支付费用， 并且每个区域`ISP`向它连接的第一层`ISP`支付费用。因此，**在这个等级结构的每一层，都有客户-提供商关系**。值得注意的是，第一层`ISP`不向任何人付费，因为它们位于该等级结构的顶部。 

**例如，在中国，每个 城市有接入`ISP`,它们与省级`ISP`连接，省级`ISP`又与国家级`ISP`连接，国家级`IS`P最终与 第一层`ISP`连接。这个多层等级结构仍然仅仅是今天因特网的粗略近似，我们称它为网络结构3。** 

### 多宿

任何`ISP` (除了第一层`ISP`)可以选择多宿(`multi-home`)，即可以**与两个或更多提供商`ISP`连接**。这被称为多宿。这样网络的可靠性就提高了

### 对等

位于相同等级结构层次的邻近一对`ISP`能够直接将它们的网络连到一起，使**它们之间的所有流量经直接连接而不是通过上游的中间`ISP`传输**。这样既不用付费，速度也快一些。

### 因特网交换点

第三方公司能够创建一个因特网交换点(`Internet Exchange Point, TXP`) , `IXP`是一个汇合点，多个`ISP` 能够在这里一起对等。

![image-20200603103543514](http://img.lijiawei0627.xyz/img/image-20200603103543514.png)

# 三、时延、丢包、吞吐量

## 时延类型

**节点处理时延、排队时延、传输时延和传播时延，这些时延总体累加起来是节点总时延**

### 处理时延

检查分组首部、决定将该分组导向何处和检查比特级别的差错所需要的时间

### 排队时延

在队列中，当分组在链路上等待传输时，它经受排队时延。

### 传输时延

将所有分组的比特推向链路(即传输，或者说发射)所需要的时间。

### 传播时延

一旦一个比特被推向链路，该比特需要向路由器B传播。从该链路的起点到路由器B 传播所需要的时间是传播时延。

## 排队时延和丢包

### 排队时延

> 假设比特到达队列的平均速率是`LabpS`，`R`是传输速率

**比率`La/R`被 称为流量强度**（traffic intensity）,它在估计排队时延的范围方面经常起着重要的作用。如果`La/R>1`,则**比特到达队列的平均速率超过从该队列传输出去的速率**。在这种不幸的情 况下，**该队列趋向于无限增加，并且排队时延将趋向无穷大**！因此，流量工程中的一条金科玉律是：**设计系统时流量强度不能大于1。**

### 丢包

在现实中，一条链路前的队列只有有限的容量，尽管排队容量极大地依赖于路由器设计和成本。**因为该排队容量是 有限的**，随着流量强度接近1,排队时延并不真正趋向无穷大。相反，**到达的分组将发现 一个满的队列。由于没有地方存储这个分组，路由器将丢弃(drop)该分组，即该分组将会丢失(lost)** 

## 吞吐量

令`Rs`表示服务器与路由器之间的链路速率；`Rc`表示路由器与客户之间的链路速率。那么其吞吐量是`min{Rc，Rs}`，它**是瓶颈链路 （bottleneck link）的传输速率**

**在今天因特网中对吞吐量的限制因素通常是接入网**

# 四、协议层次

## 应用层

应用层包括许多协议，例如**`HTTP` 、`SMTP` （它提供了电子邮件报文的传输）和`FTP` （它提供两个端系统之间的文件传送）、`DNS`（域名系统）**等

应用层协议分布在多个端系统上，而一个端系统中的应用程序使用协议与另一个端系统 中的应用程序交换信息分组。我们把这种位于应用层的信息分组称为**报文**

## 运输层

因特网的运输层在应用程序端点之间传送应用层报文。在因特网中，有两种运输协 议，**即`TCP和UDP`**。我们把运输层的分组称为**报文段**

### `TCP`

提供面向连接的服务。这种服务包括了应用层报文向目的地的确保传递和流量控制（即发送方/接收方速率匹配）。并提供拥塞控制机制，因此当网络拥塞时，源抑制其传输速率。

### `UDP`

提供无连接服务。这是一种不提供不必要服务的服务，没有可靠性，没有流量控制，也没有拥塞控制

## 网络层

因特网的网络层负责将称为**数据报**（datagram）的网络层分组从一台主机移动到另一 台主机。网络层包括著名的**网际协议`IP`**

## 链路层

为了将分组从一个节点（主机或路由器）移动到路径上的下一个节点，网络层必须依靠该链路层的服务。把链路层分组称为**帧**

## 物理层

**物理层的任务是将该帧中的一个个比特从一个节点移动到下一个节点**

# 五、面对攻击的网络

## 病毒

是一种需要某种形式的用户交互来感染用户设备的恶意软件

## 蠕虫

是一种无须任何明显用户交互就能进入设备的恶意软件

## 拒绝服务攻击（`DoS`）

* **弱点攻击**。这涉及向一台目标主机上运行的易受攻击的应用程序或操作系统发送 制作精细的报文。如果适当顺序的多个分组发送给一个易受攻击的应用程序或操作系统，该服务器可能停止运行，或者更糟糕的是主机可能崩溃。
* **带宽洪泛**。攻击者向目标主机发送大量的分组，分组数量之多使得目标的接入链路变得拥塞，使得合法的分组无法到达服务器。
* **连接洪泛**。攻击者在目标主机中创建大量的半开或全开TCP连接。该主机因这些伪造的连接而陷入困境，并停止接受合法的连接。

> 半连接：在TCP连接中，第三次握手中收到的`SYN`包而还未收到`ACK`包时连接状态称为半连接，即尚未完成三次握手的TCP连接

## 分布式拒绝服务攻击（`DDoS`）

攻击者控制多个源并让每个源向目标猛烈发送流量。使用这种方法，遍及所有受控源的聚合 流量速率需要大约R的能力来使该服务陷入瘫痪。`DDoS`攻击充分利用由数以千计的受害主机组成的僵尸网络，相比于来自单一主机的`DoS` 攻击，`DDoS`攻击更加难以检测和防范。

![image-20200603110840675](http://img.lijiawei0627.xyz/img/image-20200603110840675.png)

# 六、应用层

## 应用程序体系结构

* `C/S`结构
* `P2P`结构
* 混合结构

## 进程通信

### 客户与服务器进程

在一对进程之间的通信会话场景中，发起通信（即在该会话开始时发起与其他进程的联系）的进程被标识为客户，在会话开始时等待联系的进程是服务器。

### 套接字

进程通过一个称为套接字（`socket`） 的软件接口**向网络发送报文和从网络接收报文**。

套接字（`socket`）是应用程序和网络之间的应用程序编程接口（`API`），**可以控制在应用层的一切**，但是对于传输层仅限于：①选择传输层协议；②设定几个运输层参数

### 进程寻址

**`IP`地址和端口号**

## 应用程序运输服务

### 可靠数据传输

确保由应用程序的一端发送的**数据正确、完全地交付给该应用程序的另一端**。 如果一个协议提供了这样的确保数据交付服务，就认为提供了可靠数据传输

**运输层协议**能够潜在地向应用程序提供的一个重要服务是进程到进程的可靠数据传输

### 吞吐量

具有吞吐量要求的应用程序 被称为**带宽敏感的应用**

**弹性应用**（elastic application）能够根据 当时可用的带宽或多或少地利用可供使用的吞吐量

### 时延

发送方注入进套接字中的每个比特到达接收方的套接字不迟于 100ms。这种服务将对**交互式实时应用程序**有吸引力，如**因特网电话、虚拟环境、电话会 议和多方游戏**，所有这些服务为了有效性而要求数据交付有**严格的时间限制**

### 安全性

这种服务将在发送和接收进程之间提供**机密性**，以防该数据以某种方式在这两个进程之间被观察到。除了机密性 以外的其他安全性服务，包括**数据完整性和端点鉴别**

## 安全套接字层（SSL）

无论`TCP还是UDP`都没有提供任何加密机制，这就是说发送进程传进其套接字的数据，与经网络传送到目的进程的数据相同。这就可能在任何中间链路被嗅探和发现。所以因特网界已经研制了 **TCP的加强版本**。用SSL加强后的TCP不仅能够做 传统的TCP所能做的一切，而且**提供了关键的进程到进程的安全性服务，包括加密、数据完整性和端点鉴别**。

我们强调SSL不是与TCP和UDP在相同层次上的第三种因特网运输协议，而是一种**对TCP的加强**，**这种强化是在应用层上实现的**。

**当一个应用使用SSL时，发送进程向SSL套接字传递明文数据；在发送主机中的SSL则加密该数据并将加密的数据传递给TCP套接字。加密的数据经因特网传送到接收进程中的TCP套接字。该接收套接字将加密数据传递给SSL,由其进行解密。最后，SSL通过它的SSL套接字将明文数据传递给接收进程。**

# 七、WEB和HTTP

## HTTP

`HTTP`**使用`TCP`作为它的支撑运输协议(而不是在UDP上运行)**。HTTP客户首先发起一个与服务器的TCP连接。一旦 连接建立，**该浏览器和服务器进程就可以通过套接字接口访问TCP**。客户向它的套接字接口发送 HTTP请求报文并从它的套接字接口接收HTTP响应报文。类似地，服务器从它的套接字 接口接收HTTP请求报文和向它的套接字接口发送HTTP响应报文。**一旦客户向它的套接字接口发送了一个请求报文，该报文就脱离了客户控制并进入TCP的控制。**

因为HTTP服务器并不保存关于客户的任何信息，所以 我们说**HTTP是一个无状态协议**

## 非持久和持久连接

### 非持久性连接

* 每个TCP连接最多允许传输一个对象，每个对象需要两个`RTT`（Round Trip Time）
* 操作系统需要为每个TCP连接开销资源

### 持久性连接

* 发送响应后，服务器保持TCP连接的打开，后续的HTTP消息可以通过这个连接发送。

* 每个TCP连接允许传输多个对象
* HTTP 1.1版本默认使用带有流水机制的持久性连接

#### 无流水持久性连接

* 客户端只有收到前一个响应后才发送新的请求
* 每个被引用的对象耗时1个RTT

#### 带有流水机制的持久性连接

* HTTP1.1的默认选项
* 客户端只要遇到一个引用对象就尽快发出请求
* 理想情况下，收到所有的引用对象只需耗时约1个RTT

> **RTT（Round Trip Time）：指从客户端发送一个很小的数据包到服务器并返回所经历的时间**

## Cookie

### Cookie的组件

* HTTP响应消息的cookie头部行
* HTTP请求消息的Cookie头部行
* 保存在客户端主机上的cookie文件，由浏览器管理
* Web服务器端的后台数据库

### 原理

第一次访问服务器时，Cookie会根据从服务端发送的响应报文内的一个叫做**Set-Cookie**的首部字段信息，通知客户端**保存Cookie**。当下次客户端再往该服务器发送请求时，客户端会自动**在请求报文中加入Cookie值（键值对形式）**后发送出去。服务端发现客户端发送过来的Cookie后，会去检查究竟是从哪一个客户端发送过来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。

![image-20191121092909412](http://img.lijiawei0627.xyz/img/image-20191121092909412.png)

### 缺点

**存在隐私问题**

## WEB缓存

当客户端向服务器请求资源时，会先抵达浏览器缓存，如果浏览器有“要请求资源”的副本，就可以直接从浏览器缓存中提取而不是从原始服务器中提取这个资源。

### **强缓存**

浏览器直接从本地缓存中获取数据，不与服务器进行交互。

用户发起了一个http请求后，浏览器发现先本地已有所请求资源的缓存，便开始检查缓存是否过期。有两个http头部字段控制缓存的有效期：Expires和Cache-Control，浏览器是根据以下两步来判定缓存是否过期的：

**1、查看缓存是否有Cache-Control的s-maxage或max-age指令，若有，则使用响应报文生成时间Date + s-maxage/max-age获得过期时间，再与当前时间进行对比（s-maxage适用于多用户使用的公共缓存服务器）；**

**2、如果没有Cache-Control的s-maxage或max-age指令，则比较Expires中的过期时间与当前时间。Expires是一个绝对时间。**

> **注**：**从字面意思上很容易把no-cache误解成为不缓存,但事实上no-cache代表不缓存过期的资源,缓存会向源服务器进行有效期确认后处理资源,也许格do-not-serve-from-cache-without--revalidation更合适。no-store才是真正地不进行缓存**

---

### **协商缓存**

浏览器发送请求到服务器，服务器判定是否可使用本地缓存。

* **若未命中强缓存，则浏览器会将请求发送至服务器。服务器根据http头信息中的Last-Modify/If-Modify-Since或Etag/If-None-Match来判断是否命中协商缓存。如果命中，则http返回码为304，浏览器从缓存中加载资源。**

* **Last-Modify/If-Modify-Since**

  浏览器第一次请求一个资源的时候，服务器返回的header中会加上Last-Modify，Last-modify是一个时间标识该资源的最后修改时间，例如Last-Modify: Thu,31 Dec 2037 23:59:59 GMT。

* **ETag/If-None-Match**

  与Last-Modify/If-Modify-Since不同的是，Etag/If-None-Match返回的是一个校验码（ETag: entity tag）。ETag可以保证每一个资源是唯一的，资源变化都会导致ETag变化。ETag值的变更则说明资源状态已经被修改。服务器根据浏览器上发送的If-None-Match值来判断是否命中缓存。

# 八、DNS

## 域名解析系统`DNS`

* 多层命名服务器构成的分布式系统
* 应用层协议，完成域名的解析
* `DNS协议运行在UDP`之上

## `DNS`服务

* 将主机名转换为IP地址
* 主机别名
* 邮件服务器别名
* 负载均衡：Web服务器

## 分布式层次式数据库

![image-20191127202503056](http://img.lijiawei0627.xyz/img/image-20191127202503056.png)

### 为什么不使用集中式的DNS

* 单点故障
* 通信容量
* 远距离的集中式数据库
* 维护性问题

## 查询`IP`

客户端想要查询www.amazon.com的`IP`

* 客户端查询根服务器，找到`com`域名解析服务器
* 客户端查询`com`域名解析服务器，找到`amazon.com`域名解析服务器
* 客户端查询`amazon.com`域名解析服务器，获得www.amazon.com的`IP`地址

例如`Cis.poly.edu`的主机想获得`gaia.cs.umass.edu`的`IP`地址

### 根服务器（root）：

 根服务器主要用来管理互联网的主目录 

### 顶级域名服务器（`TLD`）：

负责`com，org，net，edu`等顶级域名和国籍顶级域名，例如`cn，uk，fr`等

### 权威域名服务器（Authoritative）：

组织的域名解析服务器，提供组织内部服务器的解析服务

### 迭代查询

![image-20191127203706077](http://img.lijiawei0627.xyz/img/image-20191127203706077.png)

### 递归查询

**在一个请求链中，当某DNS 服务器接收一个DNS回答(例如，包含某主机名到IP地址的映射)时，它能将映射缓存在本地存储器中。**例如，在下图中，每当本地DNS服务器dns. nyu. edu从 某个DNS服务器接收到一个回答，它能够 缓存包含在该回答中的任何信息。如果在 DNS服务器中缓存了一台主机名/IP地址 对，另一个对相同主机名的查询到达该 DNS服务器时，该DNS服务器就能够提供 所要求的IP地址，即使它不是该主机名的权威服务器。**由于主机和主机名与IP地址间的映射并不是永久的，DNS服务器在一段时间后(通常设置为两天)将丢弃缓存的信息**。 

![image-20191127203726628](http://img.lijiawei0627.xyz/img/image-20191127203726628.png)

## `DNS`记录缓存和更新

只要域名解析服务获得域名 — IP映射，即缓存这一映射

* 一段时间过后，缓存条目失效（删除）
* 本地域名服务器一般会缓存顶级域名服务器的映射
  * 因此根域名服务器不经常被访问

## `DNS`协议

* 查询（query）和回复（reply消息）
* 消息格式相同

# 九、运输层

运输层为运行在**不同主机上的应用进程提供直接的通信服务**起着至关重要的作用。

## 运输层和网络层的关系

**在协议栈中，运输层刚好位于网络层之上。网络层提供了主机之间的逻辑通信，而运输层为运行在不同主机上的进程之间提供了逻辑通信。**

我们用一个**家庭类比来帮助分析这种差别**。 考虑有两个家庭，一家位于美国东海岸，一家位于美国西海岸，每家有12个孩子。 东海岸家庭的孩子们是西海岸家庭孩子们的堂兄弟姐妹。这两个家庭的孩子们喜欢彼此通 信，每个人每星期要互相写一封信，每封信都用单独的信封通过传统的邮政服务传送。因 此，每个家庭每星期向另一家发送144封信。每一个家庭有个孩子负责收发邮件，西海岸家庭是Ann而东海岸家庭是Bill。 每星期Ann去她的所有兄弟姐妹那里收集信件，并将这些信件交到每天到家门口来的邮政服务的邮车上。当信件到达西海岸家庭时，Ann也负责将信件分发到她的兄弟姐妹手上。 在东海岸家庭中的Bill也负责类似的工作。 

​						应用层报文 = 信封上的字符

​						进程 = 堂兄弟姐妹

​						主机（端系统） = 家庭

​						运输层协议 = Ann和Bill

​						网络层协议 = 邮政服务（包括邮车）

Arm和Bill所能提供的服务明显受制于邮政服务所能提供的服务。例如，如果邮政服务不能提供在两家之间传递邮件所需时间的最长期限（例如3天），那么Ann和Bill就不 可能保证邮件在堂兄弟姐妹之间传递信件的最长期限。与此类似，**运输协议能够提供的服务常常受制于底层网络层协议的服务模型。如果网络层协议无法为主机之间发送的运输层报文段提供时延或带宽保证的话，运输层协议也就无法为进程之间发送的应用程序报文提供时延或带宽保证。**

**`UDP和TCP`最基本的责任是，将两个端系统间`IP`的交付服务扩展为运行在端系统上的两个进程之间的交付服务。**将主机间交付扩展到进程间交付被称为**运输层的多路复用与多路分解**

## 多路复用和多路分解

一个进程(作为网络应用的一部分)有一个或多个套接字 (socket)，它相当于从网络向进程传递数据和从进程向网络传递数据的门户。**在接收主机中的运输层实际上并没有直接将数据交付给进程，而是将数据交给了一个中间的套接字。**由于在任一时刻，在接收主机上可能有不止一个套接字，所以每个套接字都有唯一的标识符。

![image-20200604092902285](http://img.lijiawei0627.xyz/img/image-20200604092902285.png)

### 多路复用

**在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息(这将在以后用于分解)从而生成报文段，然后将报文段传递到网络 层，所有这些工作称为多路复用**

### 多路分解

**将运输层报文段中的数据交付到正确的套接字的工作称为多路分解**

**在主机上的每个套接字能够分配一个端口号，当报文段到达主机时，运输层检查报文段中的目的端口号，并将其定向到其相应的套接字**

回顾一下前面一节的家庭类比。每一个孩子通过他们的名字来标识。当Bill从邮递员处收到一批信件，并通过查看收信人名字而将信件亲手交付 给他的兄弟姐妹们时，他执行的就是一个分解操作。当Ann从兄弟姐妹们那里收集信件并 将它们交给邮递员时，她执行的就是一个多路复用操作。 

## 无连接运输：`UDP`

`UDP`只是做了运输协议能够做的最少工作。除了复用/分解功 能及少量的差错检测外，它几乎没有对`IP`增加别的东西。值得注意的是，**使用`UDP`时，在发送报文段之前，发送方和接收方的运输层实体之间没有握手。正因为如此，`UDP`被称为是无连接的。** 

### 什么情况适用于`UDP`

* **关于发送什么数据以及何时发送的应用层控制更为精细**

  实时应用通常要求最小的发送速率，**不希望过分地延迟报文段的传送，且能容忍一些数据丢失**，`TCP`服务模型并不是特别适合这些应用的需要

* **无须连接建立**

* **无连接状态**

* **分组首部开销小**（TCP报文段都有20字节的首部开销，而`UDP`仅有8字节 的开销）

### 潜在问题

无控制的`UDP`发送方引入的高丢包率将引起`TCP`发送方（如我们将看到的那样，TCP遇到拥塞将减小它们的发送速率）大大地减小它们的速率。因此，**`UDP` 中缺乏拥塞控制能够导致`UDP`发送方和接收方之间的高丢包率，并挤垮了 TCP会话，这 是一个潜在的严重问题**

## 面向连接运输：`TCP`

**TCP在IP不可靠的尽力而为服务之上创建了一种可靠数据传输服务**

TCP的可靠数据传输服务确保一个进程从其接收缓存中读出的数据流是**无损坏、无间隙、非冗余和按序的数据流；**即**该字节流与连接的另一方端系统发送出的字节流是完全相同。**

### 全双工服务

**如果一台主机上的进程A与另一台主机上的进程B存在一条TCP连接，那么应用层数据就可在从进程B流向进程A的同 时，也从进程A流向进程B**。TCP连接也总是**点对点**（point-to.point）的，即在**单个发送 方与单个接收方之间的连接**

### TCP报文段结构

![image-20200604102506764](http://img.lijiawei0627.xyz/img/image-20200604102506764.png)

与 `UDP` 一样，首部包括源端口号和目的端口 号，它被用于多路复用/分解来自或送到上 层应用的数据。

`TCP` 首部也包括检验和字段o。TCP报文段首部还包含下列字段： 

* **32比特的序号字段和32比特的确认号字段**。这些字段被TCP发送方和接收方用来**实现可靠数据传输服务**

* **16比特的接收窗口字段**。该字段用于流量控制。

*  **4比特的首部长度字段**。指示了以32比特的字为单位 的TCP首部长度
* 可选与变长的选项字段
* 6比特的标志字段

#### 序号和确认号

TCP报文段首部中两个最重要的字段是序号字段和确认号字段。这两个字段是**TCP可靠传输服务的关键部分**。

##### 序号

**TCP把数据看成一个无结构的、有序的字节流。因为序号是建立在传送的字节流之上，而不是建立在传送的报文段的序列之上。—个报文段的序号因此是该报文段首字节的字节流编号**。 

举例来说，假设主机A上的一个进程想通过一条TCP连接向主机B上的一个进程发送一 个数据流。主机A中的TCP将隐式地对数据流中的每一个字节编号。假定数据流由一个 **包含500 000字节的文件组成**，其**MSS为1000字节**，数据流的**首字节编号是0**。如图3-30 所示，该TCP将**为该数据流构建500个报文段**。给**第一个报文段分配序号0,第二个报文段分配序号1000,第三个报文段分配序号2000,以此类推。每一个序号被填入到相应TCP 报文段首部的序号字段中。**

![image-20200604114122296](http://img.lijiawei0627.xyz/img/image-20200604114122296.png)

##### 确认号

主机A在向主机B发送数据的同时，也许也接收来自主机B的数据(都是同一条TCP 连接的一部分)。从主机B到达的每个报文段中都有一个序号用于从B流向A的数据。**主机 A填充进报文段的确认号是主机A期望从主机B收到的下一字节的序号**。

看一些例子有助于理解实际发生的事情。**假设主机A已收到了来自主机B的编号为0 ~535的所有字节，同时假设它打算发送一个报文段给主机B。主机A等待主机B的数据流中字节536及之后的所有 字节。所以主机A就会在它发往主机B的报文段的确认号字段中填上536。** 

### 可靠数据传输（待更）

### 流量控制

一条TCP连接的每一侧主机都为该连接**设置了接收缓存**。**如果某应用程序读取数据时相对缓慢，而发送方发送得太多、太快，发送的数据就会很容易地使该连接的接收缓存溢出。**

`TCP`为它的应用程序**提供了流量控制服务以消除发送方使接收方缓存溢出的可能性**。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。

> TCP发送方也可能因为IP网络的拥塞而被遏制；这种形式的发送方的控制被称为拥塞控制

#### 接收窗口

`TCP`通过让发送方**维护一个称为接收窗口的变量来提供流量控制**。 通俗地说，**接收窗口用于给发送方一个指示——该接收方还有多少可用的缓存空间。**

#### 机制

**如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。TCP的流量控制就是利用滑动窗口机制实现的。接收方在返回的数据中会包含自己的接收窗口的大小，以控制发送方的数据发送。**

### 连接管理

![image-20200604122251009](http://img.lijiawei0627.xyz/img/image-20200604122251009.png)

> **SYN洪泛攻击：**服务器为了响应一个收到的`SYN`,分配并初始化连接变量和缓存。然后服务器发送一个SYNACK进行响应，并等待来自客户的 ACK报文段。如果某客户不发送ACK来完成该三次握手的第三步，最终（通常在一分多钟之后）服务器将终止该半开连接并回收资源。 这种TCP连接管理协议为经典的DoS攻击即SYN洪泛攻击提供了环境。在这种攻击中，攻击者发送大量的TCP SYN报文段，而不完成第三次握手的步骤。随着这种SYN报文段纷至沓来，服务器不断为这些半开连接分配资源（但从未使用），导致服务器的连接资源被消耗殆尽。

### TCP拥塞控制

**TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。**运行在发送方的**TCP拥塞控制机制跟踪一个额外的变量，即拥塞窗口**。拥塞窗口表示为cwnd,它对一个TCP发送方能向网络中发送流量的速率进行了限制。

#### 慢启动

**当一条TCP连接开始时，cwnd的值通常初始置为一个MSS的较小值**。在慢启动状态，cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加1个MSS。当该确认到达时，TCP发送方将拥塞窗口增加一个MSS,并发送出两个最大长度的报文段。这两个报文段被确认，则发送方对每个确认报 文段将拥塞窗口增加一个MSS,使得拥塞窗 口变为4个MSS,并这样下去。这一过程每过一个RTT,发送速率就翻番。因此，**TCP 发送速率起始慢，但在慢启动阶段以指数增长**。 **1MSS —> 2MSS —> 4MSS**

**何时结束这种指数增长呢？**

**首先，如果存在一个由超时指示的丢包事件（即拥塞），TCP发送方将cwnd设置为1并重新开始慢启动过程，同时将第二个状态变量的值ssthresh （"慢启动阈值”的速记） 设置为cwnd。因此，在之后的慢启动过程中，当cwnd 的值大于等于ssthresh时，结束慢启动并且TCP转移到拥塞避免模式，TCP将更为谨慎地增加cwnd。**

#### 拥塞避免

一旦进入拥塞避免状态，**`cwnd`的值大约是上次遇到拥塞时的值的一半**，即距离拥塞可能并不遥远！因此，TCP无法每过一个RTT再将cwnd的值翻番，而是采用了一种较为保守的方法，**每个RTT只将cwnd的值增加一个MSS** 

**何时结束拥塞避免的线性增长（每RTT 1MSS）呢？**

当出现超时时，TCP的拥 塞避免算法行为相同。与慢启动的情况一样，**cwnd的值被设置为1个MSS**,当丢包事件出现时，**ssthresh的值被更新为cwnd值的一半**。然而，前面讲过丢包事件也能由一个三个 、冗余ACK事件触发。在这种情况下，网络继续从发送方向接收方交付报文段（就像由收 到冗余ACK所指示的那样）。因此TCP对这种丢包事件的行为，相比于超时指示的丢包, 应当不那么剧烈：TCP将cwnd的值减半（为使测量结果更好，计及已收到的3个冗余的 ACK要加上3个MSS）,并且当收到3个冗余的ACK,将ssthresh的值记录为cwnd的值的 一半。**接下来进入快速恢复状态。** 

![](https://img-blog.csdnimg.cn/20190731165743903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

![](https://img-blog.csdnimg.cn/20190731165605396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

#### 快速重传

![](https://img-blog.csdnimg.cn/20190731184314574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

#### 快速恢复

![](https://img-blog.csdnimg.cn/20190731184640178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

![](https://img-blog.csdnimg.cn/20190731184935595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

#### 回顾

**忽略**一条连接开始时**初始的慢启动阶段**，假定丢包由3个冗余的ACK而不是超时指 示，TCP的拥塞控制是：**每个RTT内cwnd线性（加性）增加1MSS,然后出现3个冗余 ACK事件时cwnd减半（乘性减）**。因此，TCP拥塞控制常常被称为**加性增、乘性减**拥塞控制方式。

![image-20200604163540060](http://img.lijiawei0627.xyz/img/image-20200604163540060.png)

## TCP和UDP的比较

|              | UDP                                        | TCP                                    |
| :----------- | :----------------------------------------- | :------------------------------------- |
| 是否连接     | 无连接                                     | 面向连接                               |
| 是否可靠     | 不可靠传输，不使用流量控制和拥塞控制       | 可靠传输，使用流量控制和拥塞控制       |
| 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信 | 只能是一对一通信                       |
| **传输方式** | **面向报文**                               | **面向字节流**                         |
| 首部开销     | 首部开销小，仅8字节                        | 首部最小20字节，最大60字节             |
| 适用场景     | 适用于实时应用（IP电话、视频会议、直播等） | 适用于要求可靠传输的应用，例如文件传输 |

# 十、网络层

